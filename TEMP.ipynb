{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feiyang/miniconda3/envs/tombo/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#utils\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "#preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "115645it [1:24:15, 22.88it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> data written to /data/feiyang/output/:\n",
      "  - chunks.npy with shape (55769, 3600)\n",
      "  - references.npy with shape (55769, 186)\n",
      "  - reference_lengths.npy shape (55769,)\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "from tqdm import tqdm\n",
    "from itertools import islice as take\n",
    "import copy\n",
    "\n",
    "path = \"/data/yuxin/eligos_IVT/pseudoU_single_fast5/\"\n",
    "output_directory = \"/data/feiyang/output/\"\n",
    "\n",
    "\n",
    "def chunk_dataset(path, chunk_len, num_chunks=None):\n",
    "    def all_chunks():\n",
    "        for file_ in os.listdir(path):\n",
    "            if not os.path.isdir(os.path.join(path, file_)):\n",
    "                continue\n",
    "            \n",
    "            for file in os.listdir(os.path.join(path, file_)):\n",
    "                if file.endswith('.fast5'):\n",
    "                    path_ = os.path.join(path, file_)\n",
    "                    with h5py.File(os.path.join(path_, file), 'r') as fast5_file:\n",
    "                        data_path = fast5_file['Raw/Reads']\n",
    "                        try:\n",
    "                            for data in data_path:\n",
    "                                if data.startswith(\"Read\"):\n",
    "                                    # Access the Signal dataset and convert to npy array\n",
    "                                    signal = data_path[data][\"Signal\"][()]\n",
    "                            for chunk, target in get_chunks(fast5_file, regular_break_points(len(signal), chunk_len)):\n",
    "                                yield (chunk, target)\n",
    "                        except KeyError:\n",
    "                            continue\n",
    "\n",
    "    all_chunks_gen = all_chunks()\n",
    "    chunks, targets = zip(*tqdm(take(all_chunks_gen, num_chunks), total=num_chunks))\n",
    "    targets, target_lens = pad_lengths(targets)  # convert refs from ragged arrray\n",
    "    return ChunkDataSet(chunks, targets, target_lens)\n",
    "\n",
    "\n",
    "def get_chunks(fast5_file, break_points):\n",
    "    global array_start, array_target\n",
    "    sample = scale(fast5_file)\n",
    "    tmps = fast5_file[\"Analyses\"].keys()\n",
    "    Ref_to_signal = []\n",
    "    Reference = []\n",
    "    for tmp in tmps:\n",
    "        if tmp.startswith('RawGenomeCorrected'):\n",
    "            events = fast5_file[\"Analyses/\" + tmp + \"/BaseCalled_template/\"][\"Events\"][()]\n",
    "            for _, i in enumerate(events):\n",
    "                Ref_to_signal.append(i[2])\n",
    "                Reference.append(ACGT_2_num(i[4].decode()) + 1)\n",
    "\n",
    "            array_start = np.stack(Ref_to_signal, axis=0)\n",
    "            array_target = np.stack(Reference, axis=0)\n",
    "\n",
    "    pointers = array_start\n",
    "    target = array_target  # CTC convention\n",
    "    return (\n",
    "        (sample[i:j], target[ti:tj]) for (i, j), (ti, tj)\n",
    "        in zip(break_points, np.searchsorted(pointers, break_points))\n",
    "    )\n",
    "\n",
    "\n",
    "def scale(fast5_file, normalise=True):\n",
    "    \"\"\" scale and normalise a read \"\"\"\n",
    "\n",
    "    global scaled\n",
    "    reads_group = fast5_file[\"Raw/Reads\"]\n",
    "\n",
    "    # Find the sample\n",
    "    for group in reads_group:\n",
    "        if group.startswith(\"Read\"):\n",
    "            # Access the Signal dataset and convert to npy array\n",
    "            samples = reads_group[group][\"Signal\"][()]\n",
    "            # scaled = (scaling * (samples + offset)).astype(np.float32)\n",
    "\n",
    "    if normalise:\n",
    "        tmps = fast5_file[\"Analyses\"].keys()\n",
    "\n",
    "        for tmp in tmps:\n",
    "\n",
    "            if tmp.startswith('RawGenomeCorrected'):\n",
    "                scale = fast5_file[\"Analyses/\" + tmp + \"/BaseCalled_template\"].attrs[\"scale\"]\n",
    "                shift = fast5_file[\"Analyses/\" + tmp + \"/BaseCalled_template\"].attrs[\"shift\"]\n",
    "\n",
    "                return (samples - shift) / scale\n",
    "\n",
    "    return scaled\n",
    "\n",
    "\n",
    "def ACGT_2_num(char):\n",
    "    if char == 'A':\n",
    "        return 0\n",
    "    elif char == 'C':\n",
    "        return 1\n",
    "    elif char == 'G':\n",
    "        return 2\n",
    "    elif char == 'T':\n",
    "        return 3\n",
    "    else:\n",
    "        raise ValueError('Invalid input')\n",
    "\n",
    "\n",
    "# **********************************************************************************************************************************************************************\n",
    "class ChunkDataSet:\n",
    "    def __init__(self, chunks, targets, lengths):\n",
    "        self.chunks = np.expand_dims(chunks, axis=1)\n",
    "        self.targets = targets\n",
    "        self.lengths = lengths\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (\n",
    "            self.chunks[i].astype(np.float32),\n",
    "            self.targets[i].astype(np.int64),\n",
    "            self.lengths[i].astype(np.int64),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lengths)\n",
    "\n",
    "\n",
    "def regular_break_points(n, chunk_len, overlap=0, align='mid'):\n",
    "    num_chunks, remainder = divmod(n - overlap, chunk_len - overlap)\n",
    "    start = {'left': 0, 'mid': remainder // 2, 'right': remainder}[align]\n",
    "    starts = np.arange(start, start + num_chunks * (chunk_len - overlap), (chunk_len - overlap))\n",
    "    return np.vstack([starts, starts + chunk_len]).T\n",
    "\n",
    "\n",
    "def pad_lengths(ragged_array, max_len=None):\n",
    "    lengths: ndarray = np.array([len(x) for x in ragged_array], dtype=np.uint16)\n",
    "    padded = np.zeros((len(ragged_array), max_len or np.max(lengths)), dtype=ragged_array[0].dtype)\n",
    "    for x, y in zip(ragged_array, padded):\n",
    "        y[:len(x)] = x\n",
    "    return padded, lengths\n",
    "\n",
    "\n",
    "def typical_indices(x, n=2.5):\n",
    "    mu, sd = np.mean(x), np.std(x)\n",
    "    idx, = np.where((mu - n * sd < x) & (x < mu + n * sd))\n",
    "    return idx\n",
    "\n",
    "\n",
    "def filter_chunks(ds, idx):\n",
    "    filtered = ChunkDataSet(ds.chunks.squeeze(1)[idx], ds.targets[idx], ds.lengths[idx])\n",
    "    filtered.targets = filtered.targets[:, :filtered.lengths.max()]\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def save_chunks(chunks, output_directory):\n",
    "    a = chunks.chunks.squeeze(1)\n",
    "    b = chunks.targets\n",
    "    c = chunks.lengths\n",
    "    indices = c != 0\n",
    "    aa = np.compress(indices, a, axis=0)\n",
    "    bb = np.compress(indices, b, axis=0)\n",
    "    cc = np.compress(indices, c, axis=0)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    np.save(os.path.join(output_directory, \"chunks.npy\"), aa)\n",
    "    np.save(os.path.join(output_directory, \"references.npy\"), bb)\n",
    "    np.save(os.path.join(output_directory, \"reference_lengths.npy\"), cc)\n",
    "    print()\n",
    "    print(\"> data written to %s:\" % output_directory)\n",
    "    print(\"  - chunks.npy with shape\", aa.shape)\n",
    "    print(\"  - references.npy with shape\", bb.shape)\n",
    "    print(\"  - reference_lengths.npy shape\", cc.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "training_chunks = chunk_dataset(path, 3600)\n",
    "training_indices = typical_indices(training_chunks.lengths)\n",
    "training_chunks = filter_chunks(training_chunks, np.random.permutation(training_indices))\n",
    "save_chunks(training_chunks, output_directory)\n",
    "\n",
    "\n",
    "\n",
    "print(\"ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "chunks = np.load('/data/feiyang/output/chunks.npy')\n",
    "chunks = (chunks - np.min(chunks)) / (np.max(chunks) - np.min(chunks))\n",
    "\n",
    "references = np.load('/data/feiyang/output/references.npy')\n",
    "reference_lengths = np.load('/data/feiyang/output/reference_lengths.npy')\n",
    "\n",
    "#num_classes = 5  # 四个碱基类型和一个空白标签\n",
    "#references = F.one_hot(torch.LongTensor(references), num_classes=num_classes).numpy()\n",
    "\n",
    "\n",
    "train_chunks, valid_chunks, train_references, valid_references, train_reference_lengths, valid_reference_lengths = train_test_split(chunks, references, reference_lengths, test_size=0.1)\n",
    "# valid_chunks, test_chunks, valid_references, test_references, valid_reference_lengths, test_reference_lengths = train_test_split(valid_chunks, valid_references, valid_reference_lengths, test_size=0.5, random_state=20)\n",
    "output_directory=\"/data/feiyang/preprocessed/\"\n",
    "np.save(os.path.join(output_directory, \"train_chunks.npy\"), train_chunks)\n",
    "np.save(os.path.join(output_directory, \"train_references.npy\"), train_references)\n",
    "np.save(os.path.join(output_directory, \"train_reference_lengths.npy\"), train_reference_lengths)\n",
    "\n",
    "np.save(os.path.join(output_directory, \"valid_chunks.npy\"), valid_chunks)\n",
    "np.save(os.path.join(output_directory, \"valid_references.npy\"), valid_references)\n",
    "np.save(os.path.join(output_directory, \"valid_reference_lengths.npy\"), valid_reference_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer-LSTM模型\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_heads, lstm_hidden_size, lstm_layers, lstm_dropout, output_size):\n",
    "        super(TransformerLSTM, self).__init__()\n",
    "        \n",
    "        # Transformer编码器\n",
    "        self.transformer_encoder_layer = nn.TransformerEncoderLayer(d_model=input_size, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.transformer_encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # LSTM解码器\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=lstm_hidden_size, num_layers=lstm_layers, dropout=lstm_dropout, bidirectional=True)\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc = nn.Linear(lstm_hidden_size * 2, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Transformer编码器\n",
    "        x = x.permute(1, 0, 2)  # (seq_len, batch_size, input_size)\n",
    "        x = self.transformer_encoder(x)\n",
    "        \n",
    "        # LSTM解码器\n",
    "        x = x.permute(1, 0, 2)  # (batch_size, seq_len, input_size)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x.permute(0, 2, 1)  # (batch_size, output_size, seq_len)\n",
    "\n",
    "class CNNLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    (B, 1, S) -> (B, C, S_reducted)\n",
    "    \"\"\"\n",
    "    def __init__(self, line, num_classes, stride, winlen,hidden_size,lstm_layers,lstm_dropout):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(line, 4, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv1d(4, 16, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv1d(16, num_classes, kernel_size=winlen, stride=stride, padding=winlen//2)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=num_classes,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=lstm_layers,\n",
    "            dropout=lstm_dropout,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.permute(2, 0, 1) #(S_reducted, B, C)\n",
    "        S_reducted, B, _ = x.shape\n",
    "        x, _n = self.lstm(x)# (S_reducted, B, 2 * H)\n",
    "        x = x.view(S_reducted, B, 2, -1).sum(dim=2) # (S_reducted, B, H)\n",
    "        x = self.fc(x)  #(S_reducted, B, C)\n",
    "        return x.permute(1, 2, 0)#(B, C, S_reducted)\n",
    "    \n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self, input_size, num_classes):\n",
    "#         super(CNN, self).__init__()\n",
    "        \n",
    "#         self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.maxpool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "#         self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.maxpool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "#         self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "#         self.relu3 = nn.ReLU()\n",
    "#         self.maxpool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "#         self.fc = nn.Linear(in_features=64 * (input_size // 8), out_features=num_classes)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.relu1(x)\n",
    "#         x = self.maxpool1(x)\n",
    "        \n",
    "#         x = self.conv2(x)\n",
    "#         x = self.relu2(x)\n",
    "#         x = self.maxpool2(x)\n",
    "        \n",
    "#         x = self.conv3(x)\n",
    "#         x = self.relu3(x)\n",
    "#         x = self.maxpool3(x)\n",
    "        \n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.fc(x)\n",
    "        \n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RNADataset(Dataset):\n",
    "    def __init__(self, chunks, references, reference_lengths):\n",
    "        self.chunks = chunks\n",
    "        self.references = references\n",
    "        self.reference_lengths = reference_lengths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.chunks)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.chunks[index], self.references[index], self.reference_lengths[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def compute_ctc_loss(outputs, targets, target_lengths):\n",
    "    ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "    outputs = outputs.permute(2, 0, 1) #(S_reducted, B, C)\n",
    "    S_reducted, B, C =outputs.shape\n",
    "    outputs_lengths = torch.ones(B).type_as(outputs).int() * S_reducted\n",
    "    \n",
    "    \n",
    "    loss = ctc_loss(outputs, targets,outputs_lengths, target_lengths)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(batch_size,model, optimizer, criterion, dataloader, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for i, (inputs, targets, target_lengths) in enumerate(dataloader):\n",
    "        inputs, targets,target_lengths = inputs.to(torch.float32).to(device), targets.to(device),target_lengths.int().to(device)\n",
    "        #inputs torch.float32 torch.Size([B, 1, S])\n",
    "        #targets torch.int64 torch.Size([B, base_seq_len])\n",
    "        #target_lengths torch.float32  torch.Size([B])\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        #outputs torch.float32 torch.Size([B, C, S_reducted])\n",
    "        loss = criterion(outputs, targets, target_lengths)\n",
    "        if i%100==0:\n",
    "            print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "class SeqErrorRate:\n",
    "    \"\"\"Using Levenshtein distance.\"\"\"\n",
    "\n",
    "    def __init__(self, ignore_tokens=None):\n",
    "        if ignore_tokens is not None:\n",
    "            self.ignore_tokens = set(ignore_tokens)\n",
    "        else:\n",
    "            self.ignore_tokens = set()\n",
    "\n",
    "    def __call__(self, preds, targets):\n",
    "        B = preds.shape[0]\n",
    "        total_error = 0.0\n",
    "        total_length = 0\n",
    "        for i in range(B):\n",
    "            pred = [p for p in preds[i].tolist() if p not in self.ignore_tokens]\n",
    "            target = [t for t in targets[i].tolist() if t not in self.ignore_tokens]\n",
    "            distance = Levenshtein.distance(''.join([chr(c) for c in pred]), ''.join([chr(c) for c in target]))\n",
    "            error = distance / max(len(pred), len(target))\n",
    "            total_error += error\n",
    "            total_length += 1\n",
    "        return total_error / total_length\n",
    "def evaluate(batch_size,model, criterion, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_err = 0\n",
    "    true_labels = []\n",
    "    pred_probs = []\n",
    "    cal_err= SeqErrorRate(ignore_tokens=[0])\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets, target_lengths) in enumerate(dataloader):\n",
    "            inputs, targets,target_lengths = inputs.to(torch.float32).to(device), targets.to(device),target_lengths.int().to(device)\n",
    "            outputs = model(inputs)#(B, C, S_reducted)\n",
    "            loss = criterion(outputs, targets, target_lengths)\n",
    "            total_loss += loss.item()\n",
    "#             print(outputs.shape, targets.shape)\n",
    "            outputs = outputs.argmax(dim=1)\n",
    "            error = cal_err(outputs, targets)\n",
    "            total_err += error\n",
    "            \n",
    "            \n",
    "    return total_loss / len(dataloader), total_err/ len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "batch_size = 32\n",
    "input_size = 3600  # 输入信号段长度\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_chunks = np.load('/data/feiyang/preprocessed/train_chunks.npy')\n",
    "train_references = np.load('/data/feiyang/preprocessed/train_references.npy')\n",
    "train_reference_lengths = np.load('/data/feiyang/preprocessed/train_reference_lengths.npy')\n",
    "train_reference_lengths =train_reference_lengths.astype(np.int32)\n",
    "\n",
    "valid_chunks = np.load('/data/feiyang/preprocessed/valid_chunks.npy')\n",
    "valid_references = np.load('/data/feiyang/preprocessed/valid_references.npy')\n",
    "valid_reference_lengths = np.load('/data/feiyang/preprocessed/valid_reference_lengths.npy')\n",
    "valid_reference_lengths =valid_reference_lengths.astype(np.int32)\n",
    "train_dataset = RNADataset(torch.tensor(train_chunks).unsqueeze(1).to(torch.float32), torch.tensor(train_references).to(torch.int32), torch.tensor(train_reference_lengths))\n",
    "#inputs targets target_lengths torch.Size([32, 1, 3600]) torch.float32 torch.Size([32, 130]) torch.int32 torch.Size([32]) torch.int32\n",
    "\n",
    "valid_dataset = RNADataset(torch.tensor(valid_chunks).unsqueeze(1).to(torch.float32), torch.tensor(valid_references).to(torch.int32),\n",
    "                           torch.tensor(valid_reference_lengths))\n",
    "# test_dataset = RNADataset(torch.tensor(test_chunks), torch.tensor(test_references), torch.tensor(test_reference_lengths))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# model=CNNLSTM(line=line,num_classes=num_classes,stride=5,winlen=19,\n",
    "#               hidden_size=hidden_size,lstm_layers=lstm_layers,lstm_dropout=lstm_dropout).to(device)\n",
    "\n",
    "\n",
    "# for i, (inputs, targets, target_lengths) in enumerate(train_loader):\n",
    "#     print(inputs.shape,inputs.dtype, targets.shape,targets.dtype, target_lengths.shape,target_lengths.dtype)\n",
    "#     inputs, targets,target_lengths = inputs.to(device), targets.to(device),target_lengths.int().to(device)\n",
    "#     print(target_lengths.dtype)\n",
    "    \n",
    "#     outputs = model(inputs) \n",
    "    \n",
    "#     outputs = outputs.permute(2, 0, 1) #(S_reducted, B, C)\n",
    "#     S_reducted, B, C =outputs.shape\n",
    "#     outputs_lengths = torch.ones(B).type_as(outputs).int() * S_reducted\n",
    "    \n",
    "#     print(outputs_lengths.shape,outputs_lengths.dtype)\n",
    "#     loss = ctc_loss(outputs, targets,outputs_lengths, target_lengths)\n",
    "#     print(loss)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ./model/clstm_model.pth\n",
      "tensor(2.6122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.6930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.6815, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "num_epochs = 10\n",
    "line=1\n",
    "num_classes = 5  # 类别数（四个碱基和一个空白标签）\n",
    "input_size = 4  # 输入大小（A，C，G，T四个碱基）\n",
    "hidden_size = 512  # 隐状态大小\n",
    "lstm_layers = 2  # LSTM层数\n",
    "lstm_dropout=0.2\n",
    "learning_rate = 1e-4\n",
    "\n",
    "model=CNNLSTM(line=line,num_classes=num_classes,stride=5,winlen=19,\n",
    "              hidden_size=hidden_size,lstm_layers=lstm_layers,lstm_dropout=lstm_dropout).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=1, verbose=True)\n",
    "\n",
    "\n",
    "model_dir = './model'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "model_path = os.path.join(model_dir, 'clstm_model.pth')\n",
    "\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(f'Loaded model from {model_path}')\n",
    "\n",
    "# Train\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(batch_size, model, optimizer, compute_ctc_loss, train_loader, device)\n",
    "\n",
    "    valid_loss, valid_error = evaluate(batch_size, model, compute_ctc_loss, valid_loader, device)\n",
    "    scheduler.step(valid_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.3f}, Valid Loss: {valid_loss:.3f}, Valid Err: {valid_error:.3f}')\n",
    "\n",
    "    # 保存模型\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f'Saved model to {model_path}')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
